{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMxFgukcAV4ue1ufoKrm4Cz"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9ieKmdJldJh4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOzTGiZjdbuc",
        "outputId": "a7776ad8-d38d-4d9b-e236-1a72205d905b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced data augmentation for better generalization\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# Load dataset with augmentation\n",
        "train_dataset = datasets.EMNIST(\n",
        "    root='./data',\n",
        "    split='letters',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "test_dataset = datasets.EMNIST(\n",
        "    root='./data',\n",
        "    split='letters',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=test_transform\n",
        ")\n",
        "# Optimized batch size\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcbNbQeIdxKK",
        "outputId": "cf5a4d55-e6bc-489e-f544-e4150ea1ac58"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 562M/562M [00:09<00:00, 61.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OptimizedLetterCNN(nn.Module):\n",
        "    def __init__(self, num_classes=26):\n",
        "        super(OptimizedLetterCNN, self).__init__()\n",
        "\n",
        "        # Block 1: 28x28 -> 14x14\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "\n",
        "        # Block 2: 14x14 -> 7x7\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # Block 3: 7x7 -> 3x3 (with adaptive pooling)\n",
        "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(128)\n",
        "\n",
        "        # Pooling layers\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((3, 3))\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Block 2\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Block 3\n",
        "        x = F.relu(self.bn5(self.conv5(x)))\n",
        "        x = self.adaptive_pool(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Flatten and fully connected\n",
        "        x = x.view(-1, 128 * 3 * 3)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "bUl79aRreNhD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = OptimizedLetterCNN().to(device)\n",
        "# Advanced optimizer and scheduler\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
        "scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=0.01,\n",
        "    epochs=20,\n",
        "    steps_per_epoch=len(train_loader)\n",
        ")\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "f28ug7P_eSWG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, train_loader, criterion, optimizer, scheduler, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device) - 1  # Adjust labels to 0-25\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def validate_epoch(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device) - 1\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    avg_loss = test_loss / len(test_loader)\n",
        "    return avg_loss, accuracy\n"
      ],
      "metadata": {
        "id": "Zu7QksSnedIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 20\n",
        "best_accuracy = 0\n",
        "train_losses, train_accuracies = [], []\n",
        "test_losses, test_accuracies = [], []\n",
        "\n",
        "print(\"Starting training...\")\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, scheduler, device)\n",
        "    test_loss, test_acc = validate_epoch(model, test_loader, criterion, device)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_acc)\n",
        "\n",
        "    if test_acc > best_accuracy:\n",
        "        best_accuracy = test_acc\n",
        "        torch.save(model.state_dict(), 'best_emnist_model.pth')\n",
        "\n",
        "    print(f'Epoch {epoch+1:2d}: Train Acc: {train_acc:.2f}% | Test Acc: {test_acc:.2f}% | Loss: {test_loss:.4f}')\n",
        "\n",
        "print(f'\\nBest Test Accuracy: {best_accuracy:.2f}%')\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(test_losses, label='Test Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, label='Train Accuracy')\n",
        "plt.plot(test_accuracies, label='Test Accuracy')\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Load best model for inference\n",
        "model.load_state_dict(torch.load('best_emnist_model.pth'))\n",
        "final_test_loss, final_test_acc = validate_epoch(model, test_loader, criterion, device)\n",
        "print(f'Final Test Accuracy: {final_test_acc:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmI8IFVlenW1",
        "outputId": "3f5cf3c9-ac11-45d2-9bb8-2d4aba1e9a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Epoch  1: Train Acc: 57.66% | Test Acc: 88.45% | Loss: 0.3565\n",
            "Epoch  2: Train Acc: 80.27% | Test Acc: 91.46% | Loss: 0.2671\n",
            "Epoch  3: Train Acc: 82.85% | Test Acc: 91.75% | Loss: 0.2488\n",
            "Epoch  4: Train Acc: 82.51% | Test Acc: 92.14% | Loss: 0.2352\n",
            "Epoch  5: Train Acc: 80.95% | Test Acc: 91.57% | Loss: 0.2678\n",
            "Epoch  6: Train Acc: 80.11% | Test Acc: 91.28% | Loss: 0.2859\n",
            "Epoch  7: Train Acc: 80.87% | Test Acc: 90.94% | Loss: 0.2676\n",
            "Epoch  8: Train Acc: 81.47% | Test Acc: 91.83% | Loss: 0.2731\n",
            "Epoch  9: Train Acc: 82.46% | Test Acc: 91.38% | Loss: 0.2639\n",
            "Epoch 10: Train Acc: 83.52% | Test Acc: 92.24% | Loss: 0.2547\n",
            "Epoch 11: Train Acc: 84.77% | Test Acc: 93.07% | Loss: 0.2261\n",
            "Epoch 12: Train Acc: 85.71% | Test Acc: 92.31% | Loss: 0.2467\n",
            "Epoch 13: Train Acc: 87.07% | Test Acc: 93.23% | Loss: 0.2160\n",
            "Epoch 14: Train Acc: 88.23% | Test Acc: 93.15% | Loss: 0.2163\n",
            "Epoch 15: Train Acc: 89.20% | Test Acc: 93.43% | Loss: 0.1988\n",
            "Epoch 16: Train Acc: 90.00% | Test Acc: 93.97% | Loss: 0.1911\n",
            "Epoch 17: Train Acc: 90.90% | Test Acc: 93.90% | Loss: 0.1861\n",
            "Epoch 18: Train Acc: 91.56% | Test Acc: 94.12% | Loss: 0.1775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 50\n",
        "best_accuracy = 0\n",
        "train_losses, train_accuracies = [], []\n",
        "test_losses, test_accuracies = [], []\n",
        "\n",
        "print(\"Starting training...\")\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, scheduler, device)\n",
        "    test_loss, test_acc = validate_epoch(model, test_loader, criterion, device)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_acc)\n",
        "\n",
        "    if test_acc > best_accuracy:\n",
        "        best_accuracy = test_acc\n",
        "        torch.save(model.state_dict(), 'best_emnist_model.pth')\n",
        "\n",
        "    print(f'Epoch {epoch+1:2d}: Train Acc: {train_acc:.2f}% | Test Acc: {test_acc:.2f}% | Loss: {test_loss:.4f}')\n",
        "\n",
        "print(f'\\nBest Test Accuracy: {best_accuracy:.2f}%')\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(test_losses, label='Test Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, label='Train Accuracy')\n",
        "plt.plot(test_accuracies, label='Test Accuracy')\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Load best model for inference\n",
        "model.load_state_dict(torch.load('best_emnist_model.pth'))\n",
        "final_test_loss, final_test_acc = validate_epoch(model, test_loader, criterion, device)\n",
        "print(f'Final Test Accuracy: {final_test_acc:.2f}%')"
      ],
      "metadata": {
        "id": "9NV0lzRVpPxw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}